{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bitbaseconda3515d9fbd1ca42ca9e198ab902aad8a8",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Cross-validation\n",
    "\n",
    "## Cross-validation is a step in the process of building a machine learning model which helps us ensure that our mdels fit the data accurately and also ensures that we do not overfit\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the red wine data set\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"winequality-red.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load first 10 rows\n",
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be treatign this dataste as a classificaiton problem. S\n",
    "## Since it only consist of 6 types of quality values, we need to map from 0-5\n",
    "\n",
    "quality_mapping = {\n",
    "    3:0,\n",
    "    4:1,\n",
    "    5:2,\n",
    "    6:3,\n",
    "    7:4,\n",
    "    8:5\n",
    "}\n",
    "# We can use the map fxn of pandas with any disctionary to convert th evalues in a given col to values in the dictionary\n",
    "df.loc[:, \"quality\"] = df.quality.map(quality_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if mapping was successfull\n",
    "df.head(n=10)\n",
    "#df.size\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try out a Decision Tree model\n",
    "\n",
    "# Split the data into training and tets sets\n",
    "# Use sample with frac=1 to shuffle the dataframe\n",
    "# we reset the indices since they change after shuffling the dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# top 1000 rows are selected for training\n",
    "df_train = df.head(1000)\n",
    "\n",
    "#bottom 599 values selected for testing/validation\n",
    "df_test=df.tail(599)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import from scikit-learn\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "\n",
    "# initialize decision tree classifier class with a max_depth =3\n",
    "clf = tree.DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "# choose the col's you want to train on. These are the features for the model\n",
    "cols = ['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol']\n",
    "\n",
    "# train the model on these features and mapped quality from before\n",
    "clf.fit(df_train[cols], df_train.quality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we test the accuracy if this model on the training and test sets\n",
    "\n",
    "# generate predictions on the training set\n",
    "train_predictions = clf.predict(df_train[cols])\n",
    "\n",
    "# generate predictions on the test set\n",
    "test_predictions = clf.predict(df_test[cols])\n",
    "\n",
    "# calculate the accuracy of the predictions on the training set\n",
    "train_accuracy = metrics.accuracy_score(\n",
    "        df_train.quality, train_predictions\n",
    ")\n",
    "\n",
    "# calculate the accuracy of the predictions on the test set\n",
    "test_accuracy = metrics.accuracy_score(\n",
    "        df_test.quality, test_predictions\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_accuracy)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_accuracy)"
   ]
  },
  {
   "source": [
    "\n",
    "## Running the same decision tree while toggling through different depth sizes\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scikit-learn tree and metrics\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "\n",
    "# import matplotlib and seaborn for plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our global size of label text on the plots\n",
    "matplotlib.rc('xtick', labelsize=20)\n",
    "matplotlib.rc('ytick', labelsize=20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an inline item to ensure the plot is displayed inside the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store accuracies for trainign and test sets. We start with a 50% accuracy\n",
    "train_accuracies = [0.5]\n",
    "test_accuracies = [0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over a few depth values\n",
    "for depth in range(1, 25):\n",
    "    # initialize model\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=depth)\n",
    "\n",
    "    # Choose columns/features for training. This can also be done outside the loop\n",
    "    cols = ['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides',\n",
    "            'free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol'\n",
    "            ]\n",
    "\n",
    "    # train the model on these features and mapped quality from before\n",
    "    clf.fit(df_train[cols], df_train.quality)   \n",
    "\n",
    "    # Now we test the accuracy if this model on the training and test sets\n",
    "\n",
    "    # generate predictions on the training and test set\n",
    "    train_predictions = clf.predict(df_train[cols])\n",
    "    test_predictions = clf.predict(df_test[cols])\n",
    "\n",
    "    # calculate the accuracy of the predictions on the training and test set\n",
    "    train_accuracy = metrics.accuracy_score(\n",
    "            df_train.quality, train_predictions\n",
    "    )\n",
    "    test_accuracy = metrics.accuracy_score(\n",
    "            df_test.quality, test_predictions\n",
    "    )\n",
    "\n",
    "    # Append accuracies\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we test the accuracy if this model on the training and test sets\n",
    "\n",
    "# generate predictions on the training and test set\n",
    "train_predictions = clf.predict(df_train[cols])\n",
    "test_predictions = clf.predict(df_test[cols])\n",
    "\n",
    "# calculate the accuracy of the predictions on the training and test set\n",
    "train_accuracy = metrics.accuracy_score(\n",
    "        df_train.quality, train_predictions\n",
    ")\n",
    "test_accuracy = metrics.accuracy_score(\n",
    "        df_test.quality, test_predictions\n",
    ")\n",
    "\n",
    "# Append accuracies\n",
    "train_accuracies.append(train_accuracy)\n",
    "test_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two plot using matplotlib and seaborn\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.plot(train_accuracies, label=\"train accuracy\")\n",
    "plt.plot(test_accuracies, label = \"test accuracy\")\n",
    "plt.legend(loc=\"upper left\", prop={'size' : 15})\n",
    "plt.xticks(range(0, 26, 5))\n",
    "plt.xlabel(\"max_depth\", size=20)\n",
    "plt.ylabel(\"accuracy\", size=20)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# This is called Overfitting\n",
    "- This model performs poorly on the test set\n",
    "- Test loss increase as we keep improving training loss"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## K-fold Cross-Validation   \n",
    "### Divide the data into k different stes which are exclusive of each other"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas and model_selection module of scikit-learn \n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "\n",
    "# Add the ability to import this as a module later on\n",
    "if __name__ == \"__main__\":\n",
    "    # Training data is in a CSV file called train.csv\n",
    "    df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "    # we create a new col called kfold and fill it with -1\n",
    "    df[\"kfold\"]=-1\n",
    "\n",
    "    # Now we randomize the rows of the data\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # initialize the kfold class form model_selection module\n",
    "    kf = model_selection.KFold(n_splits=5)\n",
    "\n",
    "    # Fill the new kfold col\n",
    "    # Use enumerate method to add a counter to an iterable\n",
    "    for fold, (trn_, val_) in enumerate(kf.split(X=df)):\n",
    "        df.loc[val_, 'kfold'] = fold\n",
    "\n",
    "    # Save the new csv with kfold col\n",
    "    df.to_csv(\"train_folds.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}